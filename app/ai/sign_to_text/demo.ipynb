{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacefd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install onnxruntime opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88953d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(\"cv2 module path:\", cv2.__file__)\n",
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import string\n",
    "\n",
    "\n",
    "def load_labels():\n",
    "    \"\"\"Create labels for ASL alphabet\"\"\"\n",
    "    return [\n",
    "        \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\n",
    "        \"NOTHING\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"\n",
    "    ]\n",
    "\n",
    "\n",
    "def preprocess(img: np.ndarray, input_shape):\n",
    "    \"\"\"\n",
    "    Resize & normalize to [0,1], convert BGR→RGB,\n",
    "    HWC → CHW, add batch dim.\n",
    "    \"\"\"\n",
    "    _, c, h, w = input_shape  # e.g. [1,3,224,224]\n",
    "    img_resized = cv2.resize(img, (w, h))\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    chw = np.transpose(img_rgb, (2, 0, 1))\n",
    "    return np.expand_dims(chw, axis=0)  # [1,3,h,w]\n",
    "\n",
    "\n",
    "def softmax(x: np.ndarray):\n",
    "    e = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Model path - adjust this to your model location\n",
    "    model_path = \"./models/asl-v2.onnx\"\n",
    "\n",
    "    # Load class names\n",
    "    labels = load_labels()\n",
    "\n",
    "    # Create ONNX runtime session\n",
    "    print(\"Loading ONNX model...\")\n",
    "    sess = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    # Grab I/O metadata\n",
    "    input_meta = sess.get_inputs()[0]\n",
    "    input_name = input_meta.name\n",
    "    input_shape = input_meta.shape  # [batch,channel,height,width]\n",
    "    print(f\"Model expects input shape: {input_shape}\")\n",
    "\n",
    "    # Open webcam\n",
    "    print(\"Opening webcam...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to quit\")\n",
    "\n",
    "    while True:\n",
    "        # Capture frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        # Make a copy for display\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        # Preprocess frame\n",
    "        input_tensor = preprocess(frame, input_shape)\n",
    "\n",
    "        # Run inference\n",
    "        raw_outputs = sess.run(None, {input_name: input_tensor})\n",
    "        logits = raw_outputs[0]  # shape [1, NC]\n",
    "        probs = softmax(logits)  # shape [1, NC]\n",
    "\n",
    "        # Pick top‑3 predictions\n",
    "        top_indices = np.argsort(probs[0])[::-1][:3]\n",
    "\n",
    "        # Display results on frame\n",
    "        y_offset = 30\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            prob = float(probs[0, idx])\n",
    "            if prob > 0.05:  # Only show predictions with >5% confidence\n",
    "                label_text = labels[idx] if idx < len(labels) else f\"Class {idx}\"\n",
    "                text = f\"{label_text}: {prob*100:.1f}%\"\n",
    "                # Position text with increasing y offset for each prediction\n",
    "                cv2.putText(\n",
    "                    display_frame,\n",
    "                    text,\n",
    "                    (10, y_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "                y_offset += 30\n",
    "\n",
    "        # Show frame\n",
    "        cv2.imshow(\"ASL Detection\", display_frame)\n",
    "\n",
    "        # Exit on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
