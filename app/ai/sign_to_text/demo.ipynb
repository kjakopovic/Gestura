{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bacefd44",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install onnxruntime opencv-python numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88953d4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "print(\"cv2 module path:\", cv2.__file__)\n",
        "print(cv2.getBuildInformation())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ff4c19",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import string\n",
        "\n",
        "\n",
        "def load_labels():\n",
        "    \"\"\"Create labels for ASL alphabet\"\"\"\n",
        "    return [\n",
        "        \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\n",
        "        \"NOTHING\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"\n",
        "    ]\n",
        "\n",
        "\n",
        "def preprocess(img: np.ndarray, input_shape):\n",
        "    \"\"\"\n",
        "    Resize & normalize to [0,1], convert BGR→RGB,\n",
        "    HWC → CHW, add batch dim.\n",
        "    \"\"\"\n",
        "    _, c, h, w = input_shape  # e.g. [1,3,224,224]\n",
        "    img_resized = cv2.resize(img, (w, h))\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "    chw = np.transpose(img_rgb, (2, 0, 1))\n",
        "    return np.expand_dims(chw, axis=0)  # [1,3,h,w]\n",
        "\n",
        "\n",
        "def softmax(x: np.ndarray):\n",
        "    e = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return e / e.sum(axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Model path - adjust this to your model location\n",
        "    model_path = \"./models/asl-v3.onnx\"\n",
        "\n",
        "    # Load class names\n",
        "    labels = load_labels()\n",
        "\n",
        "    # Create ONNX runtime session\n",
        "    print(\"Loading ONNX model...\")\n",
        "    sess = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "    # Grab I/O metadata\n",
        "    input_meta = sess.get_inputs()[0]\n",
        "    input_name = input_meta.name\n",
        "    input_shape = input_meta.shape  # [batch,channel,height,width]\n",
        "    print(f\"Model expects input shape: {input_shape}\")\n",
        "\n",
        "    # Open webcam\n",
        "    print(\"Opening webcam...\")\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open webcam\")\n",
        "        return\n",
        "\n",
        "    print(\"Press 'q' to quit\")\n",
        "\n",
        "    while True:\n",
        "        # Capture frame\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Error: Failed to capture frame\")\n",
        "            break\n",
        "\n",
        "        # Make a copy for display\n",
        "        display_frame = frame.copy()\n",
        "\n",
        "        # Preprocess frame\n",
        "        input_tensor = preprocess(frame, input_shape)\n",
        "\n",
        "        # Run inference\n",
        "        raw_outputs = sess.run(None, {input_name: input_tensor})\n",
        "        logits = raw_outputs[0]  # shape [1, NC]\n",
        "        probs = softmax(logits)  # shape [1, NC]\n",
        "\n",
        "        # Pick top‑3 predictions\n",
        "        top_indices = np.argsort(probs[0])[::-1][:3]\n",
        "\n",
        "        # Display results on frame\n",
        "        y_offset = 30\n",
        "        for i, idx in enumerate(top_indices):\n",
        "            prob = float(probs[0, idx])\n",
        "            if prob > 0.05:  # Only show predictions with >5% confidence\n",
        "                label_text = labels[idx] if idx < len(labels) else f\"Class {idx}\"\n",
        "                text = f\"{label_text}: {prob*100:.1f}%\"\n",
        "                # Position text with increasing y offset for each prediction\n",
        "                cv2.putText(\n",
        "                    display_frame,\n",
        "                    text,\n",
        "                    (10, y_offset),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.8,\n",
        "                    (0, 255, 0),\n",
        "                    2,\n",
        "                )\n",
        "                y_offset += 30\n",
        "\n",
        "        # Show frame\n",
        "        cv2.imshow(\"ASL Detection\", display_frame)\n",
        "\n",
        "        # Exit on 'q' key press\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
