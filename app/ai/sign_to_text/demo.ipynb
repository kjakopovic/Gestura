{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacefd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install onnxruntime opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "def load_labels(path):\n",
    "    \"\"\"Each line in `path` is one class name (zero‑based index).\"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return [l.strip() for l in f if l.strip()]\n",
    "\n",
    "def preprocess(img: np.ndarray, input_shape):\n",
    "    \"\"\"\n",
    "    Resize & normalize to [0,1], convert BGR→RGB, \n",
    "    HWC → CHW, add batch dim.\n",
    "    \"\"\"\n",
    "    _, c, h, w = input_shape  # e.g. [1,3,224,224]\n",
    "    img_resized = cv2.resize(img, (w, h))\n",
    "    img_rgb     = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    chw         = np.transpose(img_rgb, (2, 0, 1))\n",
    "    return np.expand_dims(chw, axis=0)  # [1,3,h,w]\n",
    "\n",
    "def softmax(x: np.ndarray):\n",
    "    e = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "def main(model_path, image_path, labels_path):\n",
    "    # Load class names:\n",
    "    # labels = load_labels(labels_path)\n",
    "\n",
    "    # Create ONNX runtime session:\n",
    "    sess = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
    "\n",
    "    # Grab I/O metadata:\n",
    "    input_meta = sess.get_inputs()[0]\n",
    "    input_name = input_meta.name\n",
    "    input_shape = input_meta.shape  # [batch,channel,height,width]\n",
    "\n",
    "    # Load & preprocess image:\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"ERROR: cannot read '{image_path}'\")\n",
    "        sys.exit(1)\n",
    "    input_tensor = preprocess(img, input_shape)\n",
    "\n",
    "    # Run inference:\n",
    "    raw_outputs = sess.run(None, {input_name: input_tensor})\n",
    "    logits      = raw_outputs[0]            # shape [1, NC]\n",
    "    probs       = softmax(logits)           # shape [1, NC]\n",
    "\n",
    "    # Pick top‑1:\n",
    "    idx  = int(np.argmax(probs, axis=1)[0])\n",
    "    prob = float(probs[0, idx])\n",
    "\n",
    "    # Print and show:\n",
    "    print(f\"→ Predicted: {idx} ({prob*100:.2f}%)\")\n",
    "    text = f\"{idx}: {prob*100:.1f}%\"\n",
    "    cv2.putText(img, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow(\"Classification\", img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 4:\n",
    "        print(\"Usage: python classify.py <model.onnx> <image.jpg> <classes.names>\")\n",
    "        sys.exit(1)\n",
    "    main(sys.argv[1], sys.argv[2], sys.argv[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import string\n",
    "\n",
    "def load_labels():\n",
    "    \"\"\"Create labels for ASL alphabet\"\"\"\n",
    "    labels = []\n",
    "    # Add uppercase letters A-Z\n",
    "    labels.extend(list(string.ascii_uppercase))\n",
    "    # Add special classes\n",
    "    labels.extend([\"del\", \"nothing\", \"space\"])\n",
    "    return labels\n",
    "\n",
    "def preprocess(img: np.ndarray, input_shape):\n",
    "    \"\"\"\n",
    "    Resize & normalize to [0,1], convert BGR→RGB, \n",
    "    HWC → CHW, add batch dim.\n",
    "    \"\"\"\n",
    "    _, c, h, w = input_shape  # e.g. [1,3,224,224]\n",
    "    img_resized = cv2.resize(img, (w, h))\n",
    "    img_rgb     = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    chw         = np.transpose(img_rgb, (2, 0, 1))\n",
    "    return np.expand_dims(chw, axis=0)  # [1,3,h,w]\n",
    "\n",
    "def softmax(x: np.ndarray):\n",
    "    e = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "def main():\n",
    "    # Model path - adjust this to your model location\n",
    "    model_path = \"./models/best.onnx\"\n",
    "    \n",
    "    # Load class names\n",
    "    labels = load_labels()\n",
    "    \n",
    "    # Create ONNX runtime session\n",
    "    print(\"Loading ONNX model...\")\n",
    "    sess = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
    "    \n",
    "    # Grab I/O metadata\n",
    "    input_meta = sess.get_inputs()[0]\n",
    "    input_name = input_meta.name\n",
    "    input_shape = input_meta.shape  # [batch,channel,height,width]\n",
    "    print(f\"Model expects input shape: {input_shape}\")\n",
    "    \n",
    "    # Open webcam\n",
    "    print(\"Opening webcam...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"Press 'q' to quit\")\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame\")\n",
    "            break\n",
    "        \n",
    "        # Make a copy for display\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # Preprocess frame\n",
    "        input_tensor = preprocess(frame, input_shape)\n",
    "        \n",
    "        # Run inference\n",
    "        raw_outputs = sess.run(None, {input_name: input_tensor})\n",
    "        logits = raw_outputs[0]            # shape [1, NC]\n",
    "        probs = softmax(logits)           # shape [1, NC]\n",
    "        \n",
    "        # Pick top‑3 predictions\n",
    "        top_indices = np.argsort(probs[0])[::-1][:3]\n",
    "        \n",
    "        # Display results on frame\n",
    "        y_offset = 30\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            prob = float(probs[0, idx])\n",
    "            if prob > 0.05:  # Only show predictions with >5% confidence\n",
    "                label_text = labels[idx] if idx < len(labels) else f\"Class {idx}\"\n",
    "                text = f\"{label_text}: {prob*100:.1f}%\"\n",
    "                # Position text with increasing y offset for each prediction\n",
    "                cv2.putText(display_frame, text, (10, y_offset), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                y_offset += 30\n",
    "        \n",
    "        # Show frame\n",
    "        cv2.imshow(\"ASL Detection\", display_frame)\n",
    "        \n",
    "        # Exit on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
